{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53395b63-3d3c-43c4-a5be-63d889844ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 01:01:15,167 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:15,171 - INFO - train_file num : 40\n",
      "2023-08-26 01:01:15,172 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:15,174 - INFO - train_file num : 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 80/80 [00:03<00:00, 22.67it/s]\n",
      "2023-08-26 01:01:18,710 - INFO - save_pickle -> ./pickle_pretrain_v3/pretrain_('fan', 'valve').pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 397.7478 - val_loss: 37.5931\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 19.6205 - val_loss: 21.1764\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.4674 - val_loss: 21.0841\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 16.4065 - val_loss: 20.8935\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.3774 - val_loss: 21.0192\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.3545 - val_loss: 20.9423\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.3360 - val_loss: 20.9841\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.3229 - val_loss: 20.9138\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.3111 - val_loss: 20.9217\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.2981 - val_loss: 20.7871\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.2825 - val_loss: 20.7017\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.2637 - val_loss: 20.6580\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.2299 - val_loss: 20.8504\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.1448 - val_loss: 20.6996\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.9035 - val_loss: 20.3580\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.4807 - val_loss: 19.9318\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.1909 - val_loss: 19.9614\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.0754 - val_loss: 19.8345\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.9913 - val_loss: 20.0370\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.9192 - val_loss: 20.0304\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.7846 - val_loss: 20.2701\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5295 - val_loss: 20.0872\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.0643 - val_loss: 19.3138\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 13.5965 - val_loss: 18.3949\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.3152 - val_loss: 17.8467\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.1685 - val_loss: 17.4917\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.0876 - val_loss: 17.3024\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.0581 - val_loss: 17.1072\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.0460 - val_loss: 16.9717\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.0241 - val_loss: 17.0051\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.0119 - val_loss: 17.0087\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.0059 - val_loss: 16.9894\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9969 - val_loss: 16.9744\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9860 - val_loss: 17.0010\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9774 - val_loss: 17.0897\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9740 - val_loss: 17.0292\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 12.9660 - val_loss: 16.9117\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9543 - val_loss: 16.9728\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9371 - val_loss: 17.0554\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9301 - val_loss: 16.9766\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9169 - val_loss: 16.9145\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.8950 - val_loss: 17.0325\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.8739 - val_loss: 16.9951\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.8477 - val_loss: 16.8547\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 12.8176 - val_loss: 16.9664\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.8012 - val_loss: 16.8858\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.7591 - val_loss: 16.7986\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.7040 - val_loss: 16.7690\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.6474 - val_loss: 16.8215\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.5851 - val_loss: 16.5565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baejs\\anaconda3\\envs\\bae\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2023-08-26 01:01:27,704 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:27,705 - INFO - train_file num : 40\n",
      "2023-08-26 01:01:27,706 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:27,708 - INFO - train_file num : 40\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 81.60it/s]\n",
      "2023-08-26 01:01:28,696 - INFO - save_pickle -> ./pickle_pretrain_v3/pretrain_('fan', 'slider').pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 399.9060 - val_loss: 31.1731\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 17.6025 - val_loss: 19.9424\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.9510 - val_loss: 19.6899\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 14.8514 - val_loss: 19.4717\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.8181 - val_loss: 19.5987\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.7994 - val_loss: 19.7577\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.7861 - val_loss: 19.4626\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.7719 - val_loss: 19.5594\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.7534 - val_loss: 19.5528\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.7350 - val_loss: 19.4265\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6959 - val_loss: 19.3532\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6038 - val_loss: 18.7843\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.3887 - val_loss: 18.2575\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.9021 - val_loss: 16.8341\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.1426 - val_loss: 15.1241\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.2446 - val_loss: 13.9704\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.8335 - val_loss: 13.6585\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.6994 - val_loss: 13.5532\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.6056 - val_loss: 13.3590\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.5134 - val_loss: 13.3612\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.4767 - val_loss: 13.5904\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.4392 - val_loss: 13.1642\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 11.3954 - val_loss: 13.2514\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.3737 - val_loss: 13.1817\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.3497 - val_loss: 13.2999\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2959 - val_loss: 12.8104\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2312 - val_loss: 12.6763\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.1159 - val_loss: 12.2213\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.9410 - val_loss: 11.5400\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.7399 - val_loss: 11.4777\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.6494 - val_loss: 11.5553\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.5854 - val_loss: 11.6560\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.5223 - val_loss: 11.7028\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.4979 - val_loss: 11.8318\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.4406 - val_loss: 11.7700\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.4104 - val_loss: 11.8604\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.3818 - val_loss: 11.9772\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.3236 - val_loss: 11.9046\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 10.2746 - val_loss: 11.9744\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.2294 - val_loss: 11.9335\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.1882 - val_loss: 11.9764\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.1466 - val_loss: 11.9748\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.1174 - val_loss: 12.1160\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.0747 - val_loss: 12.0196\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.0317 - val_loss: 11.9965\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.9952 - val_loss: 12.0114\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.9746 - val_loss: 11.8596\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.9452 - val_loss: 11.9842\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.9058 - val_loss: 11.8319\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.8933 - val_loss: 11.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 01:01:37,270 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:37,271 - INFO - train_file num : 40\n",
      "2023-08-26 01:01:37,272 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:37,274 - INFO - train_file num : 40\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 82.55it/s]\n",
      "2023-08-26 01:01:38,252 - INFO - save_pickle -> ./pickle_pretrain_v3/pretrain_('fan', 'pump').pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 340.1379 - val_loss: 22.9196\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.5783 - val_loss: 16.1634\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.7075 - val_loss: 16.0828\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6630 - val_loss: 15.9746\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6446 - val_loss: 15.8903\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6247 - val_loss: 15.9146\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6021 - val_loss: 15.9726\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5710 - val_loss: 15.8257\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5180 - val_loss: 15.8473\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.4295 - val_loss: 15.6910\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.2068 - val_loss: 15.1645\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.8246 - val_loss: 12.5649\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.9522 - val_loss: 12.0983\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.8274 - val_loss: 11.9274\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.7827 - val_loss: 11.8729\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.6943 - val_loss: 11.6433\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.5876 - val_loss: 11.5413\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.5127 - val_loss: 11.4181\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.4482 - val_loss: 11.3490\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 11.3972 - val_loss: 11.1256\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.3736 - val_loss: 11.4074\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.3335 - val_loss: 11.3020\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.3178 - val_loss: 11.1905\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2917 - val_loss: 11.2909\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2722 - val_loss: 11.3202\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2624 - val_loss: 11.2210\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2362 - val_loss: 11.3951\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2285 - val_loss: 11.5442\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2045 - val_loss: 11.0869\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.1762 - val_loss: 11.2192\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.1533 - val_loss: 11.4715\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.1313 - val_loss: 11.4699\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.1016 - val_loss: 11.3649\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.0799 - val_loss: 11.1801\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.0232 - val_loss: 11.4969\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.9908 - val_loss: 11.2602\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 10.9557 - val_loss: 11.2574\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.9065 - val_loss: 11.2438\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.8956 - val_loss: 11.2709\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.8235 - val_loss: 11.3735\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.7847 - val_loss: 11.1321\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.7688 - val_loss: 11.3255\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.7169 - val_loss: 11.4792\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.7276 - val_loss: 11.5319\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.6611 - val_loss: 11.4351\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.6264 - val_loss: 11.3970\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.6051 - val_loss: 11.3210\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.5989 - val_loss: 11.5524\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.5606 - val_loss: 11.5162\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 10.5438 - val_loss: 11.2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 01:01:46,767 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:46,769 - INFO - train_file num : 40\n",
      "2023-08-26 01:01:46,770 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:46,772 - INFO - train_file num : 40\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 83.21it/s]\n",
      "2023-08-26 01:01:47,742 - INFO - save_pickle -> ./pickle_pretrain_v3/pretrain_('valve', 'slider').pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 451.4029 - val_loss: 29.7913\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 21.5337 - val_loss: 17.6241\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.8023 - val_loss: 17.5085\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.7291 - val_loss: 17.4960\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.7075 - val_loss: 17.3697\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.6941 - val_loss: 17.3502\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.6782 - val_loss: 17.3601\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.6572 - val_loss: 17.2822\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.6344 - val_loss: 17.3617\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.5981 - val_loss: 17.2781\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.5473 - val_loss: 17.2426\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.4615 - val_loss: 17.0147\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.3123 - val_loss: 16.8325\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.0486 - val_loss: 16.3155\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 17.5664 - val_loss: 15.5991\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.8825 - val_loss: 14.7336\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.1895 - val_loss: 14.0301\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.7109 - val_loss: 13.7029\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.4469 - val_loss: 13.4334\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.3198 - val_loss: 13.4243\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.2595 - val_loss: 13.3751\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.2260 - val_loss: 13.2812\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.1984 - val_loss: 13.2654\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.1744 - val_loss: 13.2881\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.1471 - val_loss: 13.2960\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 15.1123 - val_loss: 13.1762\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.0685 - val_loss: 13.0389\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.0043 - val_loss: 12.9741\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.9358 - val_loss: 12.8370\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.8528 - val_loss: 12.6749\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.7875 - val_loss: 12.6279\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 14.7322 - val_loss: 12.5626\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6995 - val_loss: 12.5195\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6874 - val_loss: 12.4306\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.6271 - val_loss: 12.4197\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5979 - val_loss: 12.3595\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5763 - val_loss: 12.3085\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 14.5484 - val_loss: 12.2538\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5330 - val_loss: 12.2620\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5094 - val_loss: 12.0263\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5168 - val_loss: 12.1600\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.4843 - val_loss: 12.1611\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.4357 - val_loss: 11.9625\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.4076 - val_loss: 12.0102\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.3681 - val_loss: 11.8716\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.3518 - val_loss: 11.9536\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.3202 - val_loss: 11.8540\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.2883 - val_loss: 11.8221\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 14.2553 - val_loss: 11.7975\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.2330 - val_loss: 11.8329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 01:01:56,485 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:56,487 - INFO - train_file num : 40\n",
      "2023-08-26 01:01:56,488 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:01:56,489 - INFO - train_file num : 40\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 81.68it/s]\n",
      "2023-08-26 01:01:57,478 - INFO - save_pickle -> ./pickle_pretrain_v3/pretrain_('valve', 'pump').pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 335.5670 - val_loss: 26.0777\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 19.7621 - val_loss: 19.4220\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.2305 - val_loss: 19.6173\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.1798 - val_loss: 19.4274\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.1437 - val_loss: 19.3858\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 18.1059 - val_loss: 19.3478\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 18.0647 - val_loss: 19.4407\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 18.0099 - val_loss: 19.3134\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 17.9265 - val_loss: 19.0146\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 17.7734 - val_loss: 18.4111\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 17.4756 - val_loss: 17.8666\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9284 - val_loss: 16.4465\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.1952 - val_loss: 14.6107\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.5766 - val_loss: 13.3866\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 15.1565 - val_loss: 12.6307\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 14.8535 - val_loss: 12.2599\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.5797 - val_loss: 11.8795\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.2730 - val_loss: 11.4699\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.9374 - val_loss: 11.2394\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.5923 - val_loss: 11.0561\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.2589 - val_loss: 10.8410\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9855 - val_loss: 10.5847\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.7748 - val_loss: 10.4966\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.6230 - val_loss: 10.4653\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 12.5136 - val_loss: 10.2848\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.4343 - val_loss: 10.3502\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.3749 - val_loss: 10.2305\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.3322 - val_loss: 10.1716\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.2938 - val_loss: 10.0966\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 12.2541 - val_loss: 10.0813\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 12.2106 - val_loss: 10.1117\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 12.1576 - val_loss: 10.1089\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 12.0929 - val_loss: 9.8925\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.0247 - val_loss: 9.8868\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.9438 - val_loss: 9.8944\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.8731 - val_loss: 9.8799\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.8254 - val_loss: 9.8344\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.7566 - val_loss: 10.0020\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.6984 - val_loss: 9.9986\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 11.6629 - val_loss: 10.0552\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.6192 - val_loss: 10.1043\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.5738 - val_loss: 10.0164\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.5336 - val_loss: 10.0867\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.4941 - val_loss: 10.1309\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.4536 - val_loss: 9.9402\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.3814 - val_loss: 9.8946\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.2669 - val_loss: 9.8076\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.1822 - val_loss: 9.7452\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.1196 - val_loss: 9.9129\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 11.0757 - val_loss: 9.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 01:02:06,388 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:02:06,390 - INFO - train_file num : 40\n",
      "2023-08-26 01:02:06,391 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 01:02:06,393 - INFO - train_file num : 40\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 83.35it/s]\n",
      "2023-08-26 01:02:07,362 - INFO - save_pickle -> ./pickle_pretrain_v3/pretrain_('slider', 'pump').pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 342.3042 - val_loss: 27.9313\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 19.2352 - val_loss: 18.5275\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 17.1468 - val_loss: 18.4584\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 17.0674 - val_loss: 18.2816\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 17.0299 - val_loss: 18.4125\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 17.0071 - val_loss: 18.2190\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9939 - val_loss: 18.2456\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9848 - val_loss: 18.2914\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9749 - val_loss: 18.2107\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9710 - val_loss: 18.3746\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9595 - val_loss: 18.0745\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9480 - val_loss: 18.2089\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9338 - val_loss: 18.2177\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.9086 - val_loss: 18.1220\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.8718 - val_loss: 17.9462\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.7942 - val_loss: 17.6744\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.6236 - val_loss: 17.0908\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 16.2240 - val_loss: 15.7840\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 15.4701 - val_loss: 14.3365\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 14.4484 - val_loss: 12.7522\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.8336 - val_loss: 12.4726\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.8015 - val_loss: 12.2735\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.7846 - val_loss: 12.2365\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.7720 - val_loss: 12.2740\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.7643 - val_loss: 12.3219\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.7502 - val_loss: 12.1020\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.7273 - val_loss: 12.0471\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.7141 - val_loss: 12.0436\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.6985 - val_loss: 12.0350\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 13.6832 - val_loss: 12.0098\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.6617 - val_loss: 12.1717\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.6475 - val_loss: 12.0518\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.6180 - val_loss: 12.0063\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.5766 - val_loss: 11.9946\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.5338 - val_loss: 12.0158\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.4811 - val_loss: 12.0236\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 13.4290 - val_loss: 12.0296\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.3640 - val_loss: 11.8981\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.3011 - val_loss: 11.8090\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.2411 - val_loss: 12.0390\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.1916 - val_loss: 11.8759\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.1494 - val_loss: 11.9411\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.1128 - val_loss: 11.9515\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.0858 - val_loss: 11.6497\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 13.0544 - val_loss: 11.4184\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9886 - val_loss: 11.2610\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9572 - val_loss: 11.3487\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9481 - val_loss: 11.3191\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9311 - val_loss: 11.3214\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 12.9245 - val_loss: 11.5611\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# import python-library\n",
    "########################################################################\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "import yaml\n",
    "import logging\n",
    "import keras\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "from itertools import combinations\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# setup STD I/O\n",
    "########################################################################\n",
    "# 로깅을 설정하고 초기화하는 부분\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"make_pretrain_v3.log\")\n",
    "logger = logging.getLogger(' ')\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# file I/O\n",
    "########################################################################\n",
    "#파일 입출력 관련 함수 선언 부분\n",
    "def save_pickle(filename, save_data):  \n",
    "    logger.info(\"save_pickle -> {}\".format(filename))\n",
    "    with open(filename, 'wb') as sf:\n",
    "        pickle.dump(save_data, sf)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    logger.info(\"load_pickle <- {}\".format(filename))\n",
    "    with open(filename, 'rb') as lf:\n",
    "        load_data = pickle.load(lf)\n",
    "    return load_data\n",
    "\n",
    "\n",
    "def file_load(wav_name, mono=False):\n",
    "    try:\n",
    "        return librosa.load(wav_name, sr=None, mono=mono)\n",
    "    except:\n",
    "        logger.error(\"file_broken or not exists!! : {}\".format(wav_name))\n",
    "\n",
    "\n",
    "def demux_wav(wav_name, channel=0):\n",
    "    try:\n",
    "        multi_channel_data, sr = file_load(wav_name)\n",
    "        if multi_channel_data.ndim <= 1:\n",
    "            return sr, multi_channel_data\n",
    "        return sr, np.array(multi_channel_data)[channel, :]\n",
    "    except ValueError as msg:\n",
    "        logger.warning(f'{msg}')\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# feature extractor\n",
    "########################################################################\n",
    "#소리 파일 하나를 로그멜스펙트로그램 형태로 바꾸고 딥러닝 모델에 넣을 형태로 바꾸는 함수 \n",
    "def file_to_vector_array(file_name, n_mels=64, frames=5, n_fft=1024, hop_length=512, power=2.0):\n",
    "    dims = n_mels * frames\n",
    "    sr, y = demux_wav(file_name)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, power=power)\n",
    "    log_mel_spectrogram = 20.0 / power * np.log10(mel_spectrogram + sys.float_info.epsilon)\n",
    "    vectorarray_size = len(log_mel_spectrogram[0, :]) - frames + 1\n",
    "    if vectorarray_size < 1:\n",
    "        return np.empty((0, dims), float)\n",
    "    vectorarray = np.zeros((vectorarray_size, dims), float)\n",
    "    for t in range(frames):\n",
    "        vectorarray[:, n_mels * t: n_mels * (t + 1)] = log_mel_spectrogram[:, t: t + vectorarray_size].T \n",
    "    return vectorarray\n",
    "\n",
    "#소리 파일들의 이름명이 담긴 리스트를 입력하면 그것들을 하나의 데이터셋으로 합치는 함수\n",
    "def list_to_vector_array(file_list, msg=\"calc...\", n_mels=64, frames=5, n_fft=1024, hop_length=512, power=2.0):\n",
    "    dims = n_mels * frames\n",
    "    for idx in tqdm(range(len(file_list)), desc=msg):\n",
    "        vector_array = file_to_vector_array(file_list[idx], n_mels=n_mels, frames=frames, n_fft=n_fft, hop_length=hop_length,power=power)\n",
    "        if idx == 0:\n",
    "            dataset = np.zeros((vector_array.shape[0] * len(file_list), dims), float)\n",
    "        dataset[vector_array.shape[0] * idx: vector_array.shape[0] * (idx + 1), :] = vector_array       \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def dataset_generator(target_dir, machine_type, normal_dir_name=\"normal\", ext=\"wav\"):\n",
    "    logger.info(\"target_dir : {}\".format(target_dir))\n",
    "    train_files = []\n",
    "    machine_id = f\"-6dB_{machine_type}\"\n",
    "    machine = f\"{machine_type}\"\n",
    "    id_list = [\"id_00\", \"id_02\", \"id_04\", \"id_06\"]\n",
    "    machine_type_path = os.path.join(target_dir, machine_id, machine)\n",
    "    for id_ in id_list:\n",
    "        machine_id = f\"{id_}\"\n",
    "        machine_id_path = os.path.join(machine_type_path, machine_id, normal_dir_name)\n",
    "        normal_files = sorted(glob.glob(os.path.join(machine_id_path, f\"*.{ext}\")))\n",
    "        train_files.extend(normal_files)\n",
    "    logger.info(\"train_file num : {num}\".format(num=len(train_files)))\n",
    "    return train_files\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# keras model\n",
    "########################################################################\n",
    "#오토인코더 함수\n",
    "def keras_model(inputDim):\n",
    "    inputLayer = Input(shape=(inputDim,))\n",
    "    h = Dense(64, activation=\"relu\")(inputLayer)    \n",
    "    h = Dense(64, activation=\"relu\")(h)\n",
    "    h = Dense(8, activation=\"relu\")(h)\n",
    "    h = Dense(64, activation=\"relu\")(h)\n",
    "    h = Dense(64, activation=\"relu\")(h)\n",
    "    h = Dense(inputDim, activation=None)(h)\n",
    "    return Model(inputs=inputLayer, outputs=h)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# main\n",
    "########################################################################\n",
    "# 메인 실행 부분\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"make_pretrain_v3.yaml\", encoding='utf-8') as stream:\n",
    "        pretrain_v3_param = yaml.safe_load(stream)\n",
    "\n",
    "    os.makedirs(pretrain_v3_param[\"pickle_directory\"], exist_ok=True)\n",
    "    os.makedirs(pretrain_v3_param[\"model_directory\"], exist_ok=True)\n",
    "    pretrain_v3_data_dir = pretrain_v3_param[\"base_directory\"]\n",
    "    machine_types = [\"fan\", \"valve\", \"slider\", \"pump\"]\n",
    "    print(\"\\n===========================\")\n",
    "\n",
    "    # combination함수를 사용하여 macine_types에 있는 기계 타입을 2개씩 뽑음. 그리고 하나의 데이터셋으로 만든다\n",
    "    for combo in combinations(machine_types, 2):\n",
    "        combo_ = f\"{combo}\"\n",
    "        combo_train_files = []\n",
    "        \n",
    "        train_pickle = \"{pickle}/pretrain_{combo}.pickle\".format(pickle=pretrain_v3_param[\"pickle_directory\"],combo=combo_)\n",
    "        for machine_type in combo:\n",
    "            db = f\"-6dB_{machine_type}\"\n",
    "            train_files = dataset_generator(pretrain_v3_data_dir, machine_type)\n",
    "            combo_train_files.extend(train_files)\n",
    "        \n",
    "        if os.path.exists(train_pickle):\n",
    "            train_data = load_pickle(train_pickle)\n",
    "        else: \n",
    "            train_data = list_to_vector_array(combo_train_files,\n",
    "                                          msg=\"generate train_dataset\",\n",
    "                                          n_mels=pretrain_v3_param[\"feature\"][\"n_mels\"],\n",
    "                                          frames=pretrain_v3_param[\"feature\"][\"frames\"],\n",
    "                                          n_fft=pretrain_v3_param[\"feature\"][\"n_fft\"],\n",
    "                                          hop_length=pretrain_v3_param[\"feature\"][\"hop_length\"],\n",
    "                                          power=pretrain_v3_param[\"feature\"][\"power\"])\n",
    "            save_pickle(train_pickle, train_data)\n",
    "\n",
    "        print(\"============== MODEL TRAINING ==============\")\n",
    "        model_directory = pretrain_v3_param[\"model_directory\"]\n",
    "        model_file = \"{model}/pretrain_{combo}.h5\".format(model=model_directory, combo=combo_)\n",
    "        if not os.path.exists(model_file):\n",
    "            model = keras_model(pretrain_v3_param[\"feature\"][\"n_mels\"] * pretrain_v3_param[\"feature\"][\"frames\"])\n",
    "            model.summary()\n",
    "            model.compile(**pretrain_v3_param[\"fit\"][\"compile\"])\n",
    "            model.fit(train_data,\n",
    "                      train_data,\n",
    "                      epochs=pretrain_v3_param[\"fit\"][\"epochs\"],\n",
    "                      batch_size=pretrain_v3_param[\"fit\"][\"batch_size\"],\n",
    "                      shuffle=pretrain_v3_param[\"fit\"][\"shuffle\"],\n",
    "                      validation_split=pretrain_v3_param[\"fit\"][\"validation_split\"],\n",
    "                      verbose=pretrain_v3_param[\"fit\"][\"verbose\"])\n",
    "            model.save(model_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba18483-f632-4b5a-97cd-be3d9f390103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
