{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9665a21d-4ed2-49d5-ae81-a433a42adf4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:56:24,407 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:24,407 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:24,412 - INFO - train_file num : 30\n",
      "2023-08-26 00:56:24,412 - INFO - train_file num : 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.76it/s]\n",
      "2023-08-26 00:56:26,215 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_fan_id_00.pickle\n",
      "2023-08-26 00:56:26,215 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_fan_id_00.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 15ms/step - loss: 758.2450 - val_loss: 437.9886\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 164.3209 - val_loss: 43.9199\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.2677 - val_loss: 15.4711\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3803 - val_loss: 12.7229\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.7270 - val_loss: 11.9009\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.4235 - val_loss: 11.8480\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3643 - val_loss: 11.7789\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3493 - val_loss: 11.6454\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3406 - val_loss: 11.7410\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3335 - val_loss: 11.8295\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3279 - val_loss: 11.6499\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3228 - val_loss: 11.7290\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3167 - val_loss: 11.5946\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.3122 - val_loss: 11.7811\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.3092 - val_loss: 11.7633\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3047 - val_loss: 11.5992\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3019 - val_loss: 11.7521\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2971 - val_loss: 11.6352\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2939 - val_loss: 11.7218\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2894 - val_loss: 11.6063\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.2871 - val_loss: 11.7050\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2828 - val_loss: 11.7416\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2806 - val_loss: 11.4951\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2755 - val_loss: 11.6496\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2687 - val_loss: 11.7352\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2660 - val_loss: 11.3666\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2620 - val_loss: 11.5271\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2518 - val_loss: 11.6864\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2433 - val_loss: 11.5633\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2351 - val_loss: 11.4434\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2258 - val_loss: 11.4607\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2135 - val_loss: 11.5417\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1975 - val_loss: 11.3014\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1804 - val_loss: 11.3148\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1562 - val_loss: 11.2943\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.1302 - val_loss: 11.2278\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0980 - val_loss: 11.1830\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0500 - val_loss: 11.1765\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.9948 - val_loss: 11.1531\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.9247 - val_loss: 10.8316\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.8317 - val_loss: 10.4724\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7306 - val_loss: 10.3243\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6102 - val_loss: 10.2223\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4770 - val_loss: 9.8750\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3384 - val_loss: 9.6680\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1975 - val_loss: 9.2201\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.0657 - val_loss: 9.0831\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9330 - val_loss: 8.9487\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8186 - val_loss: 8.8675\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7145 - val_loss: 8.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baejs\\anaconda3\\envs\\bae\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2023-08-26 00:56:31,190 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:31,190 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:31,192 - INFO - train_file num : 30\n",
      "2023-08-26 00:56:31,192 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 73.91it/s]\n",
      "2023-08-26 00:56:31,605 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_fan_id_02.pickle\n",
      "2023-08-26 00:56:31,605 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_fan_id_02.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 783.6656 - val_loss: 394.3726\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 158.4253 - val_loss: 45.6708\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.9992 - val_loss: 15.7045\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5720 - val_loss: 12.7013\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7895 - val_loss: 12.0120\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.4904 - val_loss: 11.7560\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.4198 - val_loss: 11.7788\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3986 - val_loss: 11.7475\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3880 - val_loss: 11.6705\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3800 - val_loss: 11.6996\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3735 - val_loss: 11.8061\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3686 - val_loss: 11.6885\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3609 - val_loss: 11.6295\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3559 - val_loss: 11.5416\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3493 - val_loss: 11.5092\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3452 - val_loss: 11.4154\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3359 - val_loss: 11.5811\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3303 - val_loss: 11.6764\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3239 - val_loss: 11.5714\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3189 - val_loss: 11.6561\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3133 - val_loss: 11.4558\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3066 - val_loss: 11.4555\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3004 - val_loss: 11.4507\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.2902 - val_loss: 11.2618\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.2827 - val_loss: 11.4519\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2734 - val_loss: 11.4346\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2596 - val_loss: 11.2945\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2505 - val_loss: 11.4652\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2321 - val_loss: 11.5135\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2151 - val_loss: 11.2360\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1929 - val_loss: 11.2437\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1632 - val_loss: 11.2489\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1328 - val_loss: 10.9831\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0965 - val_loss: 11.2194\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0443 - val_loss: 11.1649\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9796 - val_loss: 11.0726\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8899 - val_loss: 11.0584\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.7859 - val_loss: 10.8815\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6637 - val_loss: 10.7126\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.5304 - val_loss: 10.4237\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3793 - val_loss: 10.4182\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2288 - val_loss: 10.3381\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0671 - val_loss: 10.0536\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.9063 - val_loss: 9.8992\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7513 - val_loss: 9.7377\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5999 - val_loss: 9.6484\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4592 - val_loss: 9.5402\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3364 - val_loss: 9.5189\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2192 - val_loss: 9.4242\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1190 - val_loss: 9.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:56:36,305 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:36,305 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:36,307 - INFO - train_file num : 30\n",
      "2023-08-26 00:56:36,307 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 82.18it/s]\n",
      "2023-08-26 00:56:36,678 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_fan_id_04.pickle\n",
      "2023-08-26 00:56:36,678 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_fan_id_04.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 748.4152 - val_loss: 400.0898\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 155.5875 - val_loss: 44.5789\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.1385 - val_loss: 15.8371\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5225 - val_loss: 12.7879\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1666 - val_loss: 12.2023\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8555 - val_loss: 12.1158\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7876 - val_loss: 12.0725\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7630 - val_loss: 12.0315\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7442 - val_loss: 12.0510\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7240 - val_loss: 11.9576\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7042 - val_loss: 11.9439\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.6813 - val_loss: 11.9110\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.6567 - val_loss: 11.8920\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.6218 - val_loss: 11.7376\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.5812 - val_loss: 11.7666\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.5263 - val_loss: 11.6023\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.4544 - val_loss: 11.5168\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3547 - val_loss: 11.4282\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2258 - val_loss: 11.1228\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0544 - val_loss: 10.9499\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8422 - val_loss: 10.5609\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.5825 - val_loss: 10.3671\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3059 - val_loss: 9.9381\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0230 - val_loss: 9.5739\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7509 - val_loss: 9.3369\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5234 - val_loss: 9.0674\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3449 - val_loss: 8.9340\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2204 - val_loss: 8.9370\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1253 - val_loss: 8.7824\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0591 - val_loss: 8.8991\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0123 - val_loss: 8.7886\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9753 - val_loss: 8.8256\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9602 - val_loss: 8.7423\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9339 - val_loss: 8.7145\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.9162 - val_loss: 8.8628\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9012 - val_loss: 8.7932\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8862 - val_loss: 8.8030\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8664 - val_loss: 8.8650\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8556 - val_loss: 8.8827\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8428 - val_loss: 8.7846\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8268 - val_loss: 8.9545\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8077 - val_loss: 8.9608\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7914 - val_loss: 8.9486\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7707 - val_loss: 8.9343\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7479 - val_loss: 8.9787\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7227 - val_loss: 8.8716\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.6917 - val_loss: 9.0086\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.6620 - val_loss: 8.9388\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.6328 - val_loss: 8.9862\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.5964 - val_loss: 8.8622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:56:41,379 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:41,379 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:41,383 - INFO - train_file num : 30\n",
      "2023-08-26 00:56:41,383 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 84.90it/s]\n",
      "2023-08-26 00:56:41,742 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_fan_id_06.pickle\n",
      "2023-08-26 00:56:41,742 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_fan_id_06.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 19ms/step - loss: 730.9904 - val_loss: 391.6420\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 151.1901 - val_loss: 50.7702\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.1217 - val_loss: 14.8030\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1991 - val_loss: 10.7550\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.6392 - val_loss: 10.0176\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3272 - val_loss: 9.9492\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2655 - val_loss: 9.8729\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2423 - val_loss: 9.9340\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2270 - val_loss: 9.8933\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2176 - val_loss: 9.9118\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2101 - val_loss: 9.8211\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.2029 - val_loss: 9.8193\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1960 - val_loss: 9.8887\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1900 - val_loss: 9.9023\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1873 - val_loss: 9.8897\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1832 - val_loss: 9.8261\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1801 - val_loss: 9.7555\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1765 - val_loss: 9.7629\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1743 - val_loss: 9.7751\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1690 - val_loss: 9.8272\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1665 - val_loss: 9.7061\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1612 - val_loss: 9.8850\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1598 - val_loss: 9.6680\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1574 - val_loss: 9.7260\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.1527 - val_loss: 9.7280\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1465 - val_loss: 9.7988\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1428 - val_loss: 9.8103\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1372 - val_loss: 9.6948\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1311 - val_loss: 9.8214\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1235 - val_loss: 9.6184\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1149 - val_loss: 9.7877\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1109 - val_loss: 9.8594\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1017 - val_loss: 9.7267\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0839 - val_loss: 9.7206\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0746 - val_loss: 9.6936\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0563 - val_loss: 9.6402\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0395 - val_loss: 9.5838\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0137 - val_loss: 9.6902\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9838 - val_loss: 9.5572\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9457 - val_loss: 9.3709\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8994 - val_loss: 9.5207\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8408 - val_loss: 9.2330\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.7644 - val_loss: 9.0676\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6574 - val_loss: 9.0945\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.4959 - val_loss: 8.8712\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2889 - val_loss: 8.6406\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0493 - val_loss: 8.4235\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7895 - val_loss: 8.2029\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5430 - val_loss: 8.1561\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.3329 - val_loss: 8.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:56:47,036 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:47,036 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:47,039 - INFO - train_file num : 30\n",
      "2023-08-26 00:56:47,039 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 76.74it/s]\n",
      "2023-08-26 00:56:47,437 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_valve_id_00.pickle\n",
      "2023-08-26 00:56:47,437 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_valve_id_00.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 687.0162 - val_loss: 304.1858\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 137.2707 - val_loss: 42.9248\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.6530 - val_loss: 23.1346\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.7480 - val_loss: 21.0232\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.5900 - val_loss: 20.3661\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.3324 - val_loss: 20.2664\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.2724 - val_loss: 20.2412\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.2429 - val_loss: 20.2779\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.2149 - val_loss: 20.3082\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1831 - val_loss: 20.2289\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1238 - val_loss: 20.2409\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.0401 - val_loss: 20.2324\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.9101 - val_loss: 20.1131\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.7016 - val_loss: 20.0599\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.3679 - val_loss: 20.1046\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 17.8885 - val_loss: 19.9636\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.3438 - val_loss: 19.9777\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.8174 - val_loss: 19.8587\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4140 - val_loss: 19.8558\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.1450 - val_loss: 19.6934\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9572 - val_loss: 19.6748\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.8367 - val_loss: 19.6236\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.7535 - val_loss: 19.4239\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.7025 - val_loss: 19.5267\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.6698 - val_loss: 19.3507\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.6376 - val_loss: 19.3390\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.6126 - val_loss: 19.3492\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.5939 - val_loss: 19.1751\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5700 - val_loss: 19.0806\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5495 - val_loss: 19.2933\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5345 - val_loss: 19.1413\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5141 - val_loss: 18.9942\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.5003 - val_loss: 19.0925\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4721 - val_loss: 19.0616\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4506 - val_loss: 19.0348\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4322 - val_loss: 19.0450\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4089 - val_loss: 18.9144\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.3885 - val_loss: 18.9053\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3518 - val_loss: 18.8499\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3385 - val_loss: 18.8039\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2863 - val_loss: 18.8036\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2390 - val_loss: 18.7704\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1721 - val_loss: 18.5651\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1078 - val_loss: 18.4950\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.0268 - val_loss: 18.4281\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9340 - val_loss: 18.4191\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8580 - val_loss: 18.0836\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.7456 - val_loss: 18.2968\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6378 - val_loss: 17.9236\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5221 - val_loss: 17.8422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:56:52,471 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:52,471 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:52,473 - INFO - train_file num : 30\n",
      "2023-08-26 00:56:52,473 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 83.55it/s]\n",
      "2023-08-26 00:56:52,839 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_valve_id_02.pickle\n",
      "2023-08-26 00:56:52,839 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_valve_id_02.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 664.6917 - val_loss: 282.6094\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 130.6784 - val_loss: 42.0880\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.8661 - val_loss: 22.8650\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.1508 - val_loss: 20.4225\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.8114 - val_loss: 20.0454\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.5316 - val_loss: 19.9286\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.4608 - val_loss: 19.8650\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.4276 - val_loss: 19.8100\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.4052 - val_loss: 19.8455\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.3854 - val_loss: 19.7545\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.3685 - val_loss: 19.7686\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.3479 - val_loss: 19.7490\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.3318 - val_loss: 19.7690\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.3080 - val_loss: 19.7108\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.2886 - val_loss: 19.6886\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.2647 - val_loss: 19.6982\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.2370 - val_loss: 19.6249\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.2077 - val_loss: 19.7037\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.1718 - val_loss: 19.5557\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.1324 - val_loss: 19.5330\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.0812 - val_loss: 19.6406\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.0161 - val_loss: 19.4299\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.9363 - val_loss: 19.4874\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.8355 - val_loss: 19.4553\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.7077 - val_loss: 19.3745\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5508 - val_loss: 19.2818\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.3679 - val_loss: 19.1552\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.1539 - val_loss: 19.0808\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9035 - val_loss: 18.9508\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.6313 - val_loss: 18.8382\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.3523 - val_loss: 18.6489\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.0707 - val_loss: 18.5269\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.8084 - val_loss: 18.2915\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5602 - val_loss: 18.0012\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3201 - val_loss: 17.7619\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0968 - val_loss: 17.6205\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.8962 - val_loss: 17.3349\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.7135 - val_loss: 17.2434\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.5415 - val_loss: 17.0209\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3740 - val_loss: 16.7899\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.2189 - val_loss: 16.6692\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.0746 - val_loss: 16.4646\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.9346 - val_loss: 16.3895\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.8050 - val_loss: 16.2734\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.6852 - val_loss: 16.1614\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5746 - val_loss: 16.1115\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4730 - val_loss: 15.9610\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.3670 - val_loss: 15.9008\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2634 - val_loss: 15.7915\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1620 - val_loss: 15.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:56:58,115 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:58,115 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:56:58,119 - INFO - train_file num : 30\n",
      "2023-08-26 00:56:58,119 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 82.64it/s]\n",
      "2023-08-26 00:56:58,487 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_valve_id_04.pickle\n",
      "2023-08-26 00:56:58,487 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_valve_id_04.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 769.3832 - val_loss: 397.2629\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 185.4633 - val_loss: 53.8011\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 36.5274 - val_loss: 25.4087\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.5122 - val_loss: 20.8997\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 20.4868 - val_loss: 20.1140\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 20.1420 - val_loss: 20.1753\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 20.0625 - val_loss: 20.0754\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 20.0313 - val_loss: 20.0918\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.0124 - val_loss: 20.1017\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 19.9981 - val_loss: 20.0448\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.9839 - val_loss: 20.0903\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 19.9749 - val_loss: 20.1057\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 19.9650 - val_loss: 20.0725\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 19.9544 - val_loss: 20.0561\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 19.9446 - val_loss: 20.0721\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.9301 - val_loss: 19.9808\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.9203 - val_loss: 20.0207\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.9041 - val_loss: 19.9910\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.8846 - val_loss: 20.0349\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.8579 - val_loss: 20.0029\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.8243 - val_loss: 19.9564\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.7865 - val_loss: 20.0570\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.7272 - val_loss: 19.9439\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.6405 - val_loss: 19.9460\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5148 - val_loss: 20.0155\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.3437 - val_loss: 19.8394\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.1112 - val_loss: 19.8068\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.8420 - val_loss: 19.6771\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5249 - val_loss: 19.6492\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.1829 - val_loss: 19.6447\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.8360 - val_loss: 19.5940\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.5274 - val_loss: 19.4195\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2631 - val_loss: 19.3929\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0270 - val_loss: 19.2189\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8535 - val_loss: 19.1451\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7133 - val_loss: 19.0424\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6046 - val_loss: 18.9962\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5107 - val_loss: 18.8923\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4252 - val_loss: 18.6543\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3433 - val_loss: 18.6256\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2533 - val_loss: 18.4584\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1289 - val_loss: 18.1726\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9242 - val_loss: 17.9121\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5413 - val_loss: 17.1930\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.0308 - val_loss: 16.5321\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6502 - val_loss: 16.2379\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4098 - val_loss: 15.9483\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2898 - val_loss: 15.9357\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2518 - val_loss: 15.9073\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2141 - val_loss: 15.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:05,055 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:05,055 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:05,058 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:05,058 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 75.96it/s]\n",
      "2023-08-26 00:57:05,459 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_valve_id_06.pickle\n",
      "2023-08-26 00:57:05,459 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_valve_id_06.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 749.1931 - val_loss: 299.1548\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 164.0410 - val_loss: 47.5770\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.6431 - val_loss: 22.0269\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.0365 - val_loss: 19.6748\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.6100 - val_loss: 19.0683\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.3182 - val_loss: 19.0410\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.2425 - val_loss: 19.0363\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.2090 - val_loss: 19.0250\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1803 - val_loss: 18.9393\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1512 - val_loss: 18.9136\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1219 - val_loss: 18.8251\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.0915 - val_loss: 18.8596\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.0513 - val_loss: 18.8301\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.0056 - val_loss: 18.6933\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.9449 - val_loss: 18.6960\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.8575 - val_loss: 18.5217\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.7277 - val_loss: 18.3541\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5450 - val_loss: 18.0473\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.2615 - val_loss: 17.7005\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.8675 - val_loss: 17.0686\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.4106 - val_loss: 16.4012\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.9854 - val_loss: 15.8295\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6345 - val_loss: 15.4516\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4043 - val_loss: 15.3418\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2813 - val_loss: 15.1129\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1927 - val_loss: 14.9490\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1482 - val_loss: 15.1655\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1005 - val_loss: 14.8613\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0680 - val_loss: 14.9920\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0438 - val_loss: 14.9338\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0099 - val_loss: 14.9256\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9815 - val_loss: 15.0899\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9557 - val_loss: 15.0083\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9245 - val_loss: 14.7834\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.8963 - val_loss: 15.0337\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.8534 - val_loss: 14.9580\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.8208 - val_loss: 14.8582\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.7787 - val_loss: 14.8210\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.7086 - val_loss: 14.6670\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.6438 - val_loss: 14.7976\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.5749 - val_loss: 14.5606\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5007 - val_loss: 14.6175\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4037 - val_loss: 14.5031\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2949 - val_loss: 14.3195\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1816 - val_loss: 14.0926\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0621 - val_loss: 13.9501\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.9442 - val_loss: 13.7432\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.7921 - val_loss: 13.4855\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6341 - val_loss: 13.2699\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.4920 - val_loss: 13.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:10,225 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:10,225 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:10,227 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:10,227 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 81.96it/s]\n",
      "2023-08-26 00:57:10,602 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_slider_id_00.pickle\n",
      "2023-08-26 00:57:10,602 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_slider_id_00.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 901.8525 - val_loss: 556.1351\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 286.5899 - val_loss: 74.6438\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 40.1415 - val_loss: 29.8727\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.4236 - val_loss: 24.0028\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.8493 - val_loss: 23.3894\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3907 - val_loss: 23.0573\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3017 - val_loss: 23.0270\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2833 - val_loss: 23.0388\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2778 - val_loss: 23.0440\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2764 - val_loss: 23.0460\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2732 - val_loss: 22.9830\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2709 - val_loss: 23.0614\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2687 - val_loss: 23.0248\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2667 - val_loss: 23.0517\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2642 - val_loss: 23.0329\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2606 - val_loss: 23.0309\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2587 - val_loss: 23.0575\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2526 - val_loss: 22.9194\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2505 - val_loss: 23.1749\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2460 - val_loss: 22.9395\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2369 - val_loss: 22.9717\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2283 - val_loss: 22.9029\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2234 - val_loss: 22.9451\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2140 - val_loss: 22.7833\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2048 - val_loss: 23.0994\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1907 - val_loss: 22.8687\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1663 - val_loss: 22.7294\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1423 - val_loss: 22.7915\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1069 - val_loss: 22.6688\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0706 - val_loss: 22.5675\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0187 - val_loss: 22.4803\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9452 - val_loss: 22.4155\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.8488 - val_loss: 22.0990\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.7162 - val_loss: 21.9051\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5508 - val_loss: 21.6178\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3217 - val_loss: 21.0520\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.7260 - val_loss: 19.3320\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6027 - val_loss: 18.4197\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1575 - val_loss: 18.6399\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1102 - val_loss: 18.4082\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0193 - val_loss: 18.4488\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9776 - val_loss: 18.4212\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9384 - val_loss: 18.3854\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8948 - val_loss: 18.3633\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8457 - val_loss: 18.3017\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7967 - val_loss: 18.2619\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7539 - val_loss: 18.3567\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7346 - val_loss: 18.2232\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7081 - val_loss: 18.3093\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7116 - val_loss: 18.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:15,439 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:15,439 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:15,442 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:15,442 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 47.90it/s]\n",
      "2023-08-26 00:57:16,078 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_slider_id_02.pickle\n",
      "2023-08-26 00:57:16,078 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_slider_id_02.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 10ms/step - loss: 765.1042 - val_loss: 353.8225\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 168.9311 - val_loss: 58.1583\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.6613 - val_loss: 27.4646\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.7536 - val_loss: 23.4261\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.6821 - val_loss: 22.6557\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.3518 - val_loss: 22.5515\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2772 - val_loss: 22.4430\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2535 - val_loss: 22.4754\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2428 - val_loss: 22.5285\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2331 - val_loss: 22.4036\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2254 - val_loss: 22.4487\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2195 - val_loss: 22.3630\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2163 - val_loss: 22.4800\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2086 - val_loss: 22.4105\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2001 - val_loss: 22.3357\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1964 - val_loss: 22.3675\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1885 - val_loss: 22.4155\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1874 - val_loss: 22.3311\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 17.1819 - val_loss: 22.2924\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.1736 - val_loss: 22.3768\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.1703 - val_loss: 22.1381\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.1650 - val_loss: 22.3261\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.1535 - val_loss: 22.4022\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1433 - val_loss: 22.3699\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1281 - val_loss: 22.2498\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1147 - val_loss: 22.3357\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0961 - val_loss: 22.3037\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0669 - val_loss: 22.1664\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.0251 - val_loss: 22.1049\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.9765 - val_loss: 21.9445\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.9095 - val_loss: 21.8725\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8256 - val_loss: 21.4610\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7022 - val_loss: 21.3508\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5416 - val_loss: 21.2616\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3510 - val_loss: 20.8268\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.1185 - val_loss: 20.3120\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.8599 - val_loss: 19.9415\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5699 - val_loss: 19.6430\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2725 - val_loss: 19.0219\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9700 - val_loss: 18.7124\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6880 - val_loss: 18.3098\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4360 - val_loss: 18.0241\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2115 - val_loss: 17.8707\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.0260 - val_loss: 17.7008\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.8740 - val_loss: 17.5790\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7546 - val_loss: 17.5138\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6593 - val_loss: 17.4551\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5799 - val_loss: 17.3481\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5103 - val_loss: 17.4206\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4591 - val_loss: 17.4075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:21,060 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:21,060 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:21,062 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:21,062 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 82.64it/s]\n",
      "2023-08-26 00:57:21,431 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_slider_id_04.pickle\n",
      "2023-08-26 00:57:21,431 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_slider_id_04.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 750.4705 - val_loss: 345.8893\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 180.9739 - val_loss: 58.8345\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.2720 - val_loss: 26.9462\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.6081 - val_loss: 24.2261\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.9748 - val_loss: 23.4823\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.6462 - val_loss: 23.3822\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5291 - val_loss: 23.2675\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4531 - val_loss: 23.1565\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.4123 - val_loss: 23.0589\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2971 - val_loss: 23.0324\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2222 - val_loss: 22.8306\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1532 - val_loss: 22.6843\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0329 - val_loss: 22.3997\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8887 - val_loss: 22.3353\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.7155 - val_loss: 21.9629\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5061 - val_loss: 21.5833\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1989 - val_loss: 21.0868\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8334 - val_loss: 20.3854\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4536 - val_loss: 19.8232\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0119 - val_loss: 19.0304\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.6529 - val_loss: 18.6409\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.4782 - val_loss: 18.2221\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.2049 - val_loss: 17.9034\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0604 - val_loss: 17.6304\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9520 - val_loss: 17.4848\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8723 - val_loss: 17.3996\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8221 - val_loss: 17.2107\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.7761 - val_loss: 17.0333\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.7073 - val_loss: 16.8438\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6444 - val_loss: 16.6994\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.5936 - val_loss: 16.5738\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.5981 - val_loss: 16.3740\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.4921 - val_loss: 16.2243\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.4119 - val_loss: 16.0173\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3561 - val_loss: 15.8355\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2851 - val_loss: 15.5950\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1909 - val_loss: 15.3862\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1159 - val_loss: 15.1845\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0398 - val_loss: 14.9764\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.9754 - val_loss: 14.8715\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.9046 - val_loss: 14.5760\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.8434 - val_loss: 14.4117\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7375 - val_loss: 14.2734\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6701 - val_loss: 14.1164\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6397 - val_loss: 13.8796\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5411 - val_loss: 13.8138\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4630 - val_loss: 13.6094\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4033 - val_loss: 13.4847\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3380 - val_loss: 13.3777\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3320 - val_loss: 13.2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:26,162 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:26,162 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:26,165 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:26,165 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 82.65it/s]\n",
      "2023-08-26 00:57:26,534 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_slider_id_06.pickle\n",
      "2023-08-26 00:57:26,534 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_slider_id_06.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 10ms/step - loss: 729.2182 - val_loss: 314.5774\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 160.6451 - val_loss: 52.4780\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.5477 - val_loss: 23.5269\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5753 - val_loss: 20.2712\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.9253 - val_loss: 19.4682\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6590 - val_loss: 19.4149\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5953 - val_loss: 19.4476\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5667 - val_loss: 19.3764\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5355 - val_loss: 19.3546\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4964 - val_loss: 19.2883\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4461 - val_loss: 19.2340\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3110 - val_loss: 19.1261\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0616 - val_loss: 18.8446\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5945 - val_loss: 18.3925\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8876 - val_loss: 17.7368\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1624 - val_loss: 17.1766\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6117 - val_loss: 16.8253\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2936 - val_loss: 16.6376\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1494 - val_loss: 16.6637\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0649 - val_loss: 16.7070\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0386 - val_loss: 16.6535\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9947 - val_loss: 16.5957\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9898 - val_loss: 16.5690\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9735 - val_loss: 16.5073\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9594 - val_loss: 16.6964\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9583 - val_loss: 16.7391\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9535 - val_loss: 16.5247\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9340 - val_loss: 16.5641\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9370 - val_loss: 16.5293\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9244 - val_loss: 16.6339\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9135 - val_loss: 16.5286\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9070 - val_loss: 16.4577\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9002 - val_loss: 16.5631\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9219 - val_loss: 16.4566\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8772 - val_loss: 16.5472\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8394 - val_loss: 16.5799\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8163 - val_loss: 16.5246\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7857 - val_loss: 16.4488\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7446 - val_loss: 16.4941\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7123 - val_loss: 16.4525\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.6442 - val_loss: 16.4345\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.5806 - val_loss: 16.3129\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.5241 - val_loss: 16.2426\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.4157 - val_loss: 16.1052\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3195 - val_loss: 15.9821\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2306 - val_loss: 15.8767\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1118 - val_loss: 15.6798\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0224 - val_loss: 15.7005\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9346 - val_loss: 15.6075\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8273 - val_loss: 15.4858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:31,075 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:31,075 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:31,077 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:31,077 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 82.87it/s]\n",
      "2023-08-26 00:57:31,446 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_pump_id_00.pickle\n",
      "2023-08-26 00:57:31,446 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_pump_id_00.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 598.8323 - val_loss: 251.6089\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 116.7467 - val_loss: 40.8035\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.0491 - val_loss: 19.4031\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.6620 - val_loss: 16.9233\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3858 - val_loss: 16.3998\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1261 - val_loss: 16.3417\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0400 - val_loss: 16.2587\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9762 - val_loss: 16.2199\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9127 - val_loss: 16.1713\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.8410 - val_loss: 16.0846\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.6966 - val_loss: 16.0799\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5363 - val_loss: 15.9428\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.3469 - val_loss: 15.7804\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1341 - val_loss: 15.5757\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8937 - val_loss: 15.4006\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6357 - val_loss: 15.2694\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.3580 - val_loss: 15.1481\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0577 - val_loss: 14.8059\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7571 - val_loss: 14.6684\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.4638 - val_loss: 14.5428\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.1845 - val_loss: 14.2831\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9301 - val_loss: 14.1222\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7055 - val_loss: 14.0029\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.5164 - val_loss: 13.9167\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.3521 - val_loss: 13.7680\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.2223 - val_loss: 13.7207\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1255 - val_loss: 13.6648\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0477 - val_loss: 13.5172\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9669 - val_loss: 13.5274\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9115 - val_loss: 13.4113\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8750 - val_loss: 13.4553\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8371 - val_loss: 13.3803\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8012 - val_loss: 13.3974\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 11.7770 - val_loss: 13.3267\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.7447 - val_loss: 13.4244\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.7139 - val_loss: 13.2907\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.6840 - val_loss: 13.3034\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6673 - val_loss: 13.2700\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.6334 - val_loss: 13.2395\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.6008 - val_loss: 13.1768\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.5717 - val_loss: 13.2052\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.5386 - val_loss: 13.2000\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.4893 - val_loss: 13.2120\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.4459 - val_loss: 13.2468\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.4009 - val_loss: 13.1261\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.3686 - val_loss: 13.2110\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.2968 - val_loss: 13.2046\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.2612 - val_loss: 13.1994\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 11.1891 - val_loss: 13.0279\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.1211 - val_loss: 13.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:37,035 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:37,035 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:37,037 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:37,037 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 84.21it/s]\n",
      "2023-08-26 00:57:37,399 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_pump_id_02.pickle\n",
      "2023-08-26 00:57:37,399 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_pump_id_02.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 688.0891 - val_loss: 408.2942\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 208.6810 - val_loss: 80.7394\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 45.7621 - val_loss: 25.6875\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.4760 - val_loss: 18.8263\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.9294 - val_loss: 16.8924\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2581 - val_loss: 16.7785\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1391 - val_loss: 16.7246\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0845 - val_loss: 16.6740\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9903 - val_loss: 16.5701\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.7793 - val_loss: 16.2024\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2754 - val_loss: 15.6732\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.3147 - val_loss: 14.4762\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2498 - val_loss: 13.8193\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.5786 - val_loss: 13.5794\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3024 - val_loss: 13.3529\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1893 - val_loss: 13.4469\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1500 - val_loss: 13.4581\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1048 - val_loss: 13.3962\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0873 - val_loss: 13.4432\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0739 - val_loss: 13.4200\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0641 - val_loss: 13.4975\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0594 - val_loss: 13.4259\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0524 - val_loss: 13.3803\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0461 - val_loss: 13.5023\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0461 - val_loss: 13.3373\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0442 - val_loss: 13.3895\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0315 - val_loss: 13.5007\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0281 - val_loss: 13.4685\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0245 - val_loss: 13.4415\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0074 - val_loss: 13.5006\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9976 - val_loss: 13.4627\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9894 - val_loss: 13.4710\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9808 - val_loss: 13.4709\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9668 - val_loss: 13.4316\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9656 - val_loss: 13.5058\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9494 - val_loss: 13.5648\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9414 - val_loss: 13.2926\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9209 - val_loss: 13.4763\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8925 - val_loss: 13.4365\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8674 - val_loss: 13.5114\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8365 - val_loss: 13.3971\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8116 - val_loss: 13.3704\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.7597 - val_loss: 13.4891\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.7189 - val_loss: 13.3985\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6632 - val_loss: 13.2979\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6007 - val_loss: 13.2562\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.5191 - val_loss: 13.4264\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.4221 - val_loss: 13.3403\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.3273 - val_loss: 13.3470\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1981 - val_loss: 13.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:42,202 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:42,202 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:42,205 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:42,205 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 85.45it/s]\n",
      "2023-08-26 00:57:42,563 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_pump_id_04.pickle\n",
      "2023-08-26 00:57:42,563 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_pump_id_04.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 713.8832 - val_loss: 380.8976\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 164.1597 - val_loss: 49.6437\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.3004 - val_loss: 19.4300\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1918 - val_loss: 16.9371\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.7764 - val_loss: 16.3463\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4746 - val_loss: 16.1744\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4181 - val_loss: 16.1700\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4042 - val_loss: 16.1016\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3984 - val_loss: 16.0681\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3902 - val_loss: 16.0580\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3848 - val_loss: 16.1013\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3758 - val_loss: 16.0192\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3686 - val_loss: 15.9560\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3612 - val_loss: 16.0894\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3450 - val_loss: 16.0204\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3251 - val_loss: 15.9082\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3061 - val_loss: 15.8564\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2780 - val_loss: 15.7700\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2469 - val_loss: 15.6622\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1988 - val_loss: 15.7032\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1312 - val_loss: 15.5991\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0262 - val_loss: 15.1445\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8736 - val_loss: 14.7153\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.6537 - val_loss: 14.3276\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.3633 - val_loss: 14.0386\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0420 - val_loss: 14.0675\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7161 - val_loss: 13.8524\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3554 - val_loss: 13.7965\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9794 - val_loss: 13.6498\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.6036 - val_loss: 13.7285\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.2951 - val_loss: 13.6071\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0571 - val_loss: 13.6677\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8740 - val_loss: 13.3681\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.7285 - val_loss: 13.2971\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6259 - val_loss: 13.3467\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.5582 - val_loss: 13.2762\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.5060 - val_loss: 13.2202\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.4655 - val_loss: 13.2960\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.4285 - val_loss: 13.0889\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3987 - val_loss: 13.1031\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3641 - val_loss: 13.0184\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.3296 - val_loss: 12.8770\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2951 - val_loss: 13.0723\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2670 - val_loss: 12.8939\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2147 - val_loss: 12.7937\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1710 - val_loss: 12.7241\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1221 - val_loss: 12.8098\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0651 - val_loss: 12.7373\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0135 - val_loss: 12.5090\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.9639 - val_loss: 12.4617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 00:57:47,261 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:47,261 - INFO - target_dir : ../Sample_data\n",
      "2023-08-26 00:57:47,263 - INFO - train_file num : 30\n",
      "2023-08-26 00:57:47,263 - INFO - train_file num : 30\n",
      "generate train_dataset: 100%|██████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 81.71it/s]\n",
      "2023-08-26 00:57:47,636 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_pump_id_06.pickle\n",
      "2023-08-26 00:57:47,636 - INFO - save_pickle -> ./pickle_pretrain_v2/pretrain_except_-6dB_pump_id_06.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 320)               20800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50760 (198.28 KB)\n",
      "Trainable params: 50760 (198.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 10ms/step - loss: 711.8529 - val_loss: 349.7088\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 189.1991 - val_loss: 59.8721\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.5508 - val_loss: 26.7440\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.0488 - val_loss: 23.6428\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3310 - val_loss: 23.2318\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0019 - val_loss: 22.9068\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9317 - val_loss: 22.9912\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9142 - val_loss: 22.9271\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9062 - val_loss: 22.8702\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9025 - val_loss: 22.8632\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8958 - val_loss: 22.8119\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8939 - val_loss: 22.9657\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8870 - val_loss: 22.8319\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8826 - val_loss: 22.8571\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8811 - val_loss: 22.9084\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8775 - val_loss: 22.9860\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8744 - val_loss: 22.6213\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8709 - val_loss: 22.9495\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8700 - val_loss: 22.7618\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8689 - val_loss: 22.8903\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8675 - val_loss: 22.9307\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8641 - val_loss: 22.8803\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.8629 - val_loss: 22.9355\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8593 - val_loss: 23.1080\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8596 - val_loss: 22.7636\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8606 - val_loss: 23.1341\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8588 - val_loss: 23.0294\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8582 - val_loss: 22.7510\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8570 - val_loss: 22.7725\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8548 - val_loss: 22.8903\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8517 - val_loss: 22.9337\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8546 - val_loss: 23.0342\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8585 - val_loss: 23.2020\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8551 - val_loss: 22.8046\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8537 - val_loss: 23.0230\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8511 - val_loss: 22.6686\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8531 - val_loss: 22.9698\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8532 - val_loss: 22.8740\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.8512 - val_loss: 22.9546\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8532 - val_loss: 23.2171\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8554 - val_loss: 23.0309\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8510 - val_loss: 22.9559\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8495 - val_loss: 22.9424\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8527 - val_loss: 22.7116\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.8511 - val_loss: 22.8317\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8505 - val_loss: 22.6742\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8463 - val_loss: 22.6827\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8485 - val_loss: 22.9589\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8422 - val_loss: 22.9075\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8469 - val_loss: 22.5931\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# import default python-library\n",
    "########################################################################\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "import yaml\n",
    "import logging\n",
    "import keras\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# setup STD I/O\n",
    "########################################################################\n",
    "# 로깅을 설정하고 초기화하는 부분\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"make_pretrain_v2.log\")\n",
    "logger = logging.getLogger(' ')\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# file I/O\n",
    "########################################################################\n",
    "#파일 입출력 관련 함수 선언 부분\n",
    "def save_pickle(filename, save_data):  \n",
    "    logger.info(\"save_pickle -> {}\".format(filename))\n",
    "    with open(filename, 'wb') as sf:\n",
    "        pickle.dump(save_data, sf)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    logger.info(\"load_pickle <- {}\".format(filename))\n",
    "    with open(filename, 'rb') as lf:\n",
    "        load_data = pickle.load(lf)\n",
    "    return load_data\n",
    "\n",
    "\n",
    "def file_load(wav_name, mono=False):\n",
    "    try:\n",
    "        return librosa.load(wav_name, sr=None, mono=mono)\n",
    "    except:\n",
    "        logger.error(\"file_broken or not exists!! : {}\".format(wav_name))\n",
    "\n",
    "\n",
    "def demux_wav(wav_name, channel=0):\n",
    "    try:\n",
    "        multi_channel_data, sr = file_load(wav_name)\n",
    "        if multi_channel_data.ndim <= 1:\n",
    "            return sr, multi_channel_data\n",
    "        return sr, np.array(multi_channel_data)[channel, :]\n",
    "    except ValueError as msg:\n",
    "        logger.warning(f'{msg}')\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# feature extractor\n",
    "########################################################################\n",
    "#소리 파일 하나를 로그멜스펙트로그램 형태로 바꾸고 딥러닝 모델에 넣을 형태로 바꾸는 함수 \n",
    "def file_to_vector_array(file_name, n_mels=64, frames=5, n_fft=1024, hop_length=512, power=2.0):\n",
    "    dims = n_mels * frames\n",
    "    sr, y = demux_wav(file_name)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, power=power)\n",
    "    log_mel_spectrogram = 20.0 / power * np.log10(mel_spectrogram + sys.float_info.epsilon)\n",
    "    vectorarray_size = len(log_mel_spectrogram[0, :]) - frames + 1\n",
    "    if vectorarray_size < 1:\n",
    "        return np.empty((0, dims), float)\n",
    "    vectorarray = np.zeros((vectorarray_size, dims), float)\n",
    "    for t in range(frames):\n",
    "        vectorarray[:, n_mels * t: n_mels * (t + 1)] = log_mel_spectrogram[:, t: t + vectorarray_size].T\n",
    "    return vectorarray\n",
    "\n",
    "\n",
    "#소리 파일들의 이름명이 담긴 리스트를 입력하면 그것들을 하나의 데이터셋으로 합치는 함수\n",
    "def list_to_vector_array(file_list, msg=\"calc...\", n_mels=64, frames=5, n_fft=1024, hop_length=512, power=2.0):\n",
    "    dims = n_mels * frames\n",
    "    for idx in tqdm(range(len(file_list)), desc=msg):\n",
    "        vector_array = file_to_vector_array(file_list[idx], n_mels=n_mels, frames=frames, n_fft=n_fft, hop_length=hop_length, power=power)\n",
    "        if idx == 0:\n",
    "            dataset = np.zeros((vector_array.shape[0] * len(file_list), dims), float)\n",
    "        dataset[vector_array.shape[0] * idx: vector_array.shape[0] * (idx + 1), :] = vector_array\n",
    "    return dataset\n",
    "\n",
    "# 예를 들어 machine type이 fan이고 id_가 id_00일때 id_00을 제외하고 fan 02, fan 04, fan 06으로 구성된 normal 소리음 데이터셋을 만드는 함수\n",
    "def dataset_generator(target_dir, machine_type, id_, normal_dir_name=\"normal\", ext=\"wav\"):\n",
    "    logger.info(\"target_dir : {}\".format(target_dir))\n",
    "    train_files = []\n",
    "    machine_id = f\"-6dB_{machine_type}\"\n",
    "    machine = f\"{machine_type}\"\n",
    "    id_list = [\"id_00\", \"id_02\", \"id_04\", \"id_06\"]\n",
    "    machine_type_path = os.path.join(target_dir, machine_id, machine)\n",
    "    other_ids = [other_id for other_id in id_list if other_id != id_]\n",
    "    for other_id in other_ids:\n",
    "        other_machine_id = f\"{other_id}\"\n",
    "        other_id_path = os.path.join(machine_type_path, other_machine_id, normal_dir_name)\n",
    "        other_files = sorted(glob.glob(os.path.join(other_id_path, f\"*.{ext}\")))\n",
    "        train_files.extend(other_files)    \n",
    "    logger.info(\"train_file num : {num}\".format(num=len(train_files)))\n",
    "    return train_files\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# keras model\n",
    "########################################################################\n",
    "#오토인코더 함수\n",
    "def keras_model(inputDim):\n",
    "    inputLayer = Input(shape=(inputDim,))\n",
    "    h = Dense(64, activation=\"relu\")(inputLayer)    \n",
    "    h = Dense(64, activation=\"relu\")(h)\n",
    "    h = Dense(8, activation=\"relu\")(h)\n",
    "    h = Dense(64, activation=\"relu\")(h)\n",
    "    h = Dense(64, activation=\"relu\")(h)\n",
    "    h = Dense(inputDim, activation=None)(h)\n",
    "    return Model(inputs=inputLayer, outputs=h)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# main\n",
    "########################################################################\n",
    "# 메인 실행 부분\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"make_pretrain_v2.yaml\", encoding='utf-8') as stream:\n",
    "        pretrain_v2_param = yaml.safe_load(stream)\n",
    "\n",
    "    # pickle데이터, model데이터, result데이터가 저장될 파일과 폴더들 관련 변수 선언\n",
    "    os.makedirs(pretrain_v2_param[\"pickle_directory\"], exist_ok=True)\n",
    "    os.makedirs(pretrain_v2_param[\"model_directory\"], exist_ok=True)\n",
    "    \n",
    "    pretrain_v2_data_dir = pretrain_v2_param[\"base_directory\"]\n",
    "    machine_types = [\"fan\", \"valve\", \"slider\", \"pump\"]\n",
    "    id_list = [\"id_00\", \"id_02\", \"id_04\", \"id_06\"]\n",
    "    print(\"\\n===========================\")\n",
    "\n",
    "    #각 기계 타입 별, 해당 id를 제외한 나머지 id들의 normal 데이터 전체가 합쳐진 데이터를 생성하고 pretrain학습 시작 부분(위의 dataset_generator 함수 참고)\n",
    "    for machine_type in machine_types:\n",
    "        for machine_id in id_list:\n",
    "            db = f\"-6dB_{machine_type}\"\n",
    "            evaluation_result = {}\n",
    "            train_pickle = \"{pickle}/pretrain_except_{db}_{id_}.pickle\".format(pickle=pretrain_v2_param[\"pickle_directory\"],db=db, id_ = machine_id)\n",
    "            \n",
    "            #데이터셋 생성, pickle에 저장돼있다면 그것을 사용\n",
    "            if os.path.exists(train_pickle):\n",
    "                train_data = load_pickle(train_pickle)\n",
    "            else:\n",
    "                train_files = dataset_generator(pretrain_v2_data_dir, machine_type, machine_id)\n",
    "                train_data = list_to_vector_array(train_files,\n",
    "                                                  msg=\"generate train_dataset\",\n",
    "                                                  n_mels=pretrain_v2_param[\"feature\"][\"n_mels\"],\n",
    "                                                  frames=pretrain_v2_param[\"feature\"][\"frames\"],\n",
    "                                                  n_fft=pretrain_v2_param[\"feature\"][\"n_fft\"],\n",
    "                                                  hop_length=pretrain_v2_param[\"feature\"][\"hop_length\"],\n",
    "                                                  power=pretrain_v2_param[\"feature\"][\"power\"])\n",
    "                save_pickle(train_pickle, train_data)\n",
    "\n",
    "            print(\"============== MODEL TRAINING ==============\")\n",
    "            \n",
    "            model_directory = pretrain_v2_param[\"model_directory\"]\n",
    "            model_file = \"{model}/pretrain_except_{machine_type}_{machine_id}.h5\".format(model=model_directory,\n",
    "                                                                                  machine_type=machine_type,\n",
    "                                                                                  machine_id=machine_id)\n",
    "            #모델 생성, 학습, 및 저장\n",
    "            if not os.path.exists(model_file):                                                                      \n",
    "                model = keras_model(pretrain_v2_param[\"feature\"][\"n_mels\"] * pretrain_v2_param[\"feature\"][\"frames\"])\n",
    "                model.summary()\n",
    "                model.compile(**pretrain_v2_param[\"fit\"][\"compile\"])\n",
    "                model.fit(train_data,\n",
    "                                    train_data,\n",
    "                                    epochs=pretrain_v2_param[\"fit\"][\"epochs\"],\n",
    "                                    batch_size=pretrain_v2_param[\"fit\"][\"batch_size\"],\n",
    "                                    shuffle=pretrain_v2_param[\"fit\"][\"shuffle\"],\n",
    "                                    validation_split=pretrain_v2_param[\"fit\"][\"validation_split\"],\n",
    "                                    verbose=pretrain_v2_param[\"fit\"][\"verbose\"])\n",
    "                model.save(model_file)\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be034bf6-ec01-486b-a2b2-1169089c0e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "557b26f2afb0034d2b9583f22e5a96d5c2fd0b947b12212a0c5ba344d367ad03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
